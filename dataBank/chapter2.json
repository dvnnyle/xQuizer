[
  {
    "id": 1,
    "section": "2.1",
    "question": "What does the PACT framework stand for?",
    "options": [
      "People, Architecture, Content, Technology",
      "Performance, Accessibility, Consistency, Testing",
      "People, Activities, Contexts, Technologies",
      "Persons, Actions, Culture, Tools"
    ],
    "answerIndex": 2,
    "answer": "People, Activities, Contexts, Technologies",
    "explanation": "PACT is a foundational UX framework that provides a structured way to analyze design problems by examining four interconnected elements: People (who uses the system), Activities (what they do), Contexts (where and under what conditions), and Technologies (with what tools). Unlike feature-focused approaches, PACT ensures designers consider the full ecology of use.<br><br><strong>Why it matters:</strong> PACT prevents common design mistakes like assuming all users are alike or ignoring environmental constraints. It forces holistic thinking about real-world usage.<br><br><strong>Example:</strong> When designing a mobile banking app, designers use PACT to consider: People (tech-savvy millennials vs. older users with low digital literacy), Activities (checking balance, transferring money, budgeting), Contexts (on-the-go with poor signal, at home relaxed, in public with privacy concerns), Technologies (smartphone capabilities, biometric sensors, notification systems). Each element influences the others—for instance, elderly users (People) doing complex transfers (Activities) on small screens (Technology) in bright sunlight (Context) require completely different design solutions than young users at home.",
    "shortExplanation": "PACT stands for People, Activities, Contexts, Technologies."
  },
  {
    "id": 2,
    "section": "2.1",
    "question": "What is the main purpose of using the PACT framework in UX design?",
    "options": [
      "To break down messy real-world situations into manageable parts",
      "To prioritize features based on business value and user needs",
      "To document technical specifications for development teams",
      "To evaluate interface aesthetics and visual consistency"
    ],
    "answerIndex": 0,
    "answer": "To break down messy real-world situations into manageable parts",
    "explanation": "Real-world design problems are inherently messy and interconnected—they involve many stakeholders, conflicting goals, and uncertain constraints. PACT provides a systematic lens to analyze this complexity by separating concerns into four manageable dimensions without losing sight of how they interact.<br><br><strong>Without PACT:</strong> Designers might jump to solutions (lets build an app!') without understanding who will use it, why, or under what conditions. This leads to failed products that work in theory but fail in practice.<br><br><strong>With PACT:</strong> The framework forces you to ask specific questions that reveal hidden requirements and constraints early in the design process.<br><br><strong>Example:</strong> A vague problem: 'People want better train travel.' Using PACT clarifies: Who travels? (commuters need speed, tourists need guidance, disabled users need accessibility). What do they do? (buy tickets, find platforms, check delays, navigate stations). Where? (busy rush-hour stations with noise and crowds vs. quiet suburban stations). With what? (existing kiosks with poor UI, smartphones with variable connectivity, physical tickets vs. mobile passes). Now you can see that better means different things for different people in different contexts—leading to targeted solutions rather than one-size-fits-all failures.",
    "shortExplanation": "PACT helps structure messy real-world design situations into manageable parts."
  },
  {
    "id": 3,
    "section": "2.2",
    "question": "In PACT, which element focuses on the diversity of human abilities and characteristics?",
    "options": [
      "Activities",
      "Contexts",
      "Technologies",
      "People"
    ],
    "answerIndex": 3,
    "answer": "People",
    "explanation": "The People element recognizes that users are not interchangeable—they bring vastly different abilities, knowledge, and motivations to interactions. Understanding these differences is critical because designs that work for one group often exclude or frustrate others.<br><br><strong>Four key dimensions:</strong><br>• <strong>Physical:</strong> Strength, dexterity, vision, hearing vary by age, disability, temporary conditions<br>• <strong>Cognitive:</strong> Memory, attention, problem-solving abilities affect how people process information<br>• <strong>Experiential:</strong> Prior knowledge and familiarity create mental models that guide expectations<br>• <strong>Social:</strong> Cultural backgrounds, language, social roles shape how people interpret systems<br><br><strong>Why it matters:</strong> Ignoring people differences leads to exclusive design. A button too small for arthritic hands, instructions too complex for novices, or icons with culturally-specific meanings all create barriers.<br><br><strong>Example:</strong> Designing a fitness tracker: People vary dramatically—young athletes have high stamina and tech fluency but may overtrain without guidance; retirees have lower baseline fitness but value health monitoring, may struggle with small text and complex menus; wheelchair users need adapted metrics (arm workouts, wheeling distance) not step counts; competitive users want leaderboards while casual users feel discouraged by comparisons. Each group needs different features, feedback, and interface complexity.",
    "shortExplanation": "People focuses on physical, cognitive, experiential and social diversity."
  },
  {
    "id": 4,
    "section": "2.2",
    "question": "Which of the following is a cognitive characteristic of users?",
    "options": [
      "Physical dexterity and motor control",
      "Prior experience with similar systems",
      "Memory and attention abilities",
      "Visual acuity and color perception"
    ],
    "answerIndex": 2,
    "answer": "Memory and attention abilities",
    "explanation": "Cognitive characteristics refer to the mental processes people use to perceive, process, and act on information—not their prior experience, but their fundamental thinking capacities. These include working memory (how much you can hold in mind at once), attention (what you notice and focus on), problem-solving (how you figure things out), and mental models (how you understand how things work).<br><br><strong>Why it matters for design:</strong> Cognitive abilities vary between people and are limited for everyone. Poor design overloads these capacities, causing errors, frustration, and abandonment. Good design works within human cognitive constraints.<br><br><strong>Key principles:</strong><br>• Minimize working memory load (don't require users to remember information across screens)<br>• Guide attention (make important things visually prominent)<br>• Support problem-solving (provide clear feedback and recovery paths)<br>• Match mental models (make system behavior predictable based on real-world understanding)<br><br><strong>Example:</strong> A complex admin dashboard showing 50 metrics at once overwhelms working memory—users can't process or remember all that information. People with lower attention capacity might miss critical alerts buried in noise. Good design chunks related information into meaningful groups, uses visual hierarchy to guide attention to what matters now, provides context-sensitive help for problem-solving, and uses familiar organizational patterns (e.g., chronological timelines) that match existing mental models. The result: users can focus on their task, not on figuring out the interface.",
    "shortExplanation": "Cognitive characteristics include memory, attention, and problem-solving abilities."
  },
  {
    "id": 5,
    "section": "2.2",
    "question": "Why is designing for an average user considered problematic in PACT?",
    "options": [
      "Because average users rarely exist in real life",
      "Because it focuses too much on expert users",
      "Because statistical averages hide individual differences",
      "Because user research is more cost-effective"
    ],
    "answerIndex": 0,
    "answer": "Because average users rarely exist in real life",
    "explanation": "The average user is a statistical fiction that hides the real diversity of actual users. While you can calculate an average age, skill level, or frequency of use, no single person actually has all those average characteristics. More importantly, designing for the middle excludes people at both extremes.<br><br><strong>The problem:</strong> When you design for 'average technical skill,' you create interfaces too complex for novices and too simplistic for experts. When you design for 'average vision,' you exclude people with both low vision and those using high-resolution displays. Averages flatten the meaningful variation that designers must address.<br><br><strong>Better approach:</strong> Instead of averages, use personas representing real diversity in your user population. Design for specific people in specific contexts, then ensure flexibility to accommodate variation.<br><br><strong>Example:</strong> An average online shopper might be 35 years old, shops monthly, moderately tech-savvy. But this average person doesn't exist! Real users include: a 65-year-old retiree who shops weekly but struggles with small text and never used mobile apps; a 20-year-old developer who compares prices across tabs and expects instant load times; a 45-year-old parent who shops while supervising kids and needs to complete checkout quickly. Each has different needs, frustrations, and contexts. Designing for the average satisfies none of them fully. Instead, design for these specific scenarios, ensuring the interface works across this real diversity—large enough text for older eyes, fast enough for impatient users, simple enough for novices, powerful enough for experts.",
    "shortExplanation": "Real users vary widely; designing for an average ignores important differences."
  },
  {
    "id": 6,
    "section": "2.2",
    "question": "Which example best illustrates differences in experience/familiarity among users?",
    "options": [
      "Tech-savvy young adults vs. older adults new to digital banking",
      "Users working in noisy offices vs. quiet home environments",
      "Users accessing the system on mobile vs. desktop devices",
      "Frequent daily users vs. occasional monthly users"
    ],
    "answerIndex": 0,
    "answer": "Tech-savvy young adults vs. older adults new to digital banking",
    "explanation": "Experience and familiarity shape how people approach and understand systems. This is distinct from cognitive ability—a highly intelligent novice still lacks the mental models and shortcuts that make experts efficient. Experience creates expectations, vocabulary, and confidence that fundamentally change how someone interacts with technology.<br><br><strong>Novice vs. Expert differences:</strong><br>• <strong>Mental models:</strong> Novices don't know how the system works; experts have detailed internal maps<br>• <strong>Vocabulary:</strong> Novices need plain language; experts expect technical terms<br>• <strong>Strategies:</strong> Novices explore cautiously and fear mistakes; experts move confidently and use shortcuts<br>• <strong>Goals:</strong> Novices want to complete one task safely; experts want efficiency and power<br><br><strong>Design implications:</strong> Novices need guidance, clear labels, confirmation dialogs, and safe exploration. Experts need speed, keyboard shortcuts, batch operations, and customization. Good design accommodates both without compromising either.<br><br><strong>Example:</strong> Young adults comfortable with mobile banking navigate complex hierarchical menus intuitively—they've internalized patterns from years of app use, understand swipe gestures instinctively, and grasp banking terminology. They can complete a transfer in seconds using mental shortcuts. Older adults new to digital banking see the same interface but lack these mental models—they don't know where to find transfer options, swipe gestures are unfamiliar, terms like payee are confusing, and they worry about making costly mistakes. They need: clearer task-based navigation (Send Money), larger tap targets, plain language (person youre paying'), visible buttons instead of hidden gestures, and confirmation screens that explain what will happen. The experience gap is not about intelligence—it's about accumulated knowledge that shapes perception and behavior.",
    "shortExplanation": "Novices and experts have very different mental models and needs."
  },
  {
    "id": 7,
    "section": "2.2",
    "question": "Personality and motivation in PACT mainly affect:",
    "options": [
      "How willing and confident users are in using a system",
      "The physical ergonomics of device interaction",
      "The technical performance and response times",
      "The visual hierarchy of interface elements"
    ],
    "answerIndex": 0,
    "answer": "How willing and confident users are in using a system",
    "explanation": "Personality traits and motivation levels profoundly affect how people engage with systems—not just what they can do, but whether they choose to try, how they respond to setbacks, and how much effort they invest. These psychological factors are often overlooked but critically shape user behavior.<br><br><strong>Key dimensions:</strong><br>• <strong>Confidence:</strong> Self-assured users explore freely; anxious users stick to known paths and fear errors<br>• <strong>Motivation:</strong> Highly motivated users persist through frustration; unmotivated users abandon quickly<br>• <strong>Risk tolerance:</strong> Some users experiment boldly; others need safety nets and reassurance<br>• <strong>Patience:</strong> Varies by personality, context, and stakes—affects tolerance for complexity and delays<br><br><strong>Design implications:</strong> For anxious users, provide clear undo, visible confirmations, and encouraging feedback. For unmotivated users, reduce friction and show immediate value. For exploratory users, reveal advanced features gradually.<br><br><strong>Example:</strong> Confident users explore banking apps boldly—trying features, checking settings, experimenting with transfers. They recover from errors easily because they trust they can undo mistakes. Anxious users, especially with financial apps where errors feel catastrophic, move cautiously—they stick to familiar tasks, read every word carefully, and seek constant confirmation. They need: prominent Undo buttons (showing it's safe to try things), clear confirmation screens (Youre about to transfer £50 to John Smith. This will happen immediately. Cancel | Confirm'), friendly error messages that don't blame (That account number doesnt match. Check the number and try again.'), and visible safety features (All transfers require your fingerprint). Without this reassurance, anxious users either won't adopt the system or will use it minimally, losing the full benefit.",
    "shortExplanation": "Motivation and confidence shape how users approach tasks."
  },
  {
    "id": 8,
    "section": "2.3",
    "question": "In PACT, activities refer to:",
    "options": [
      "The organizational workflows and approval processes",
      "The system's technical capabilities and limitations",
      "The business objectives and strategic initiatives",
      "What users actually do and how they do it"
    ],
    "answerIndex": 3,
    "answer": "What users actually do and how they do it",
    "explanation": "Activities are what users actually do with a system—their tasks, goals, and the steps they take to accomplish them. Understanding activities is crucial because the same technology can support vastly different activities, each requiring different design approaches. Activities are not just features—they're goal-directed behaviors happening in real contexts.<br><br><strong>Why it matters:</strong> Design must support the full activity, not just isolated actions. If users are interrupted mid-task, can they resume? If a task has 10 steps, does the system make the sequence clear? If goals change mid-activity, can users adapt?<br><br><strong>Key activity characteristics:</strong><br>• Complexity (simple vs. multi-step)<br>• Frequency (daily routine vs. rare exception)<br>• Duration (seconds vs. hours)<br>• Time pressure (urgent vs. leisurely)<br>• Structure (rigid steps vs. creative exploration)<br><br><strong>Example:</strong> In a recipe app, activities include searching for recipes (quick, exploratory, browsing-focused), saving favorites (instant action, building personal library), checking ingredients while shopping (rapid lookup, often one-handed in busy stores), and following step-by-step cooking instructions (sequential, hands-free viewing, timer integration). Each activity has different goals and constraints. Search needs visual browsing; shopping needs quick scanning; cooking needs large text visible from a distance, voice control, and timers that don't require touching the screen with messy hands. Supporting all these activities requires understanding what users do, not just what features to include.",
    "shortExplanation": "Activities are what users do: their tasks, goals and steps."
  },
  {
    "id": 9,
    "section": "2.3",
    "question": "Which of the following is an activity characteristic described in the chapter?",
    "options": [
      "Device capabilities and screen dimensions",
      "Complexity, frequency and time pressure",
      "User demographics and skill levels",
      "Environmental noise and lighting conditions"
    ],
    "answerIndex": 1,
    "answer": "Complexity, frequency and time pressure",
    "explanation": "Activities have distinct characteristics that profoundly affect design requirements. The same user might perform simple frequent activities that require speed and the removal of friction, alongside complex infrequent activities that require extensive guidance and safety nets. Designers must understand these characteristics to provide appropriate support.<br><br><strong>Key dimensions:</strong><br>• <strong>Complexity:</strong> Simple tasks need minimal interface; complex tasks need structure, progress indicators, help<br>• <strong>Frequency:</strong> Frequent tasks need shortcuts and efficiency; rare tasks need clarity and reminders<br>• <strong>Time pressure:</strong> Urgent tasks need speed and default options; leisurely tasks can offer more choices<br>• <strong>Consequences:</strong> High-stakes tasks need confirmation and undo; low-stakes can be more forgiving<br><br><strong>Example:</strong> Checking email is simple (scan subject lines, open, reply), frequent (multiple times daily), low pressure (can respond later), and low consequence (easy to undo). Design should prioritize speed: swipe gestures, minimal taps, keyboard shortcuts. Filing taxes online is complex (many interconnected forms, calculations), infrequent (once yearly, users forget process), deadline pressure (late fees create stress), and high consequence (errors are costly). Tax software must provide: step-by-step wizards that remember where you left off, extensive validation ('This number seems unusually high, please confirm'), contextual help explaining terminology, prominent save buttons, and review screens before submission. Using email design patterns for tax filing would fail catastrophically.",
    "shortExplanation": "Activities vary in complexity, frequency, and time pressure."
  },
  {
    "id": 10,
    "section": "2.3",
    "question": "Buying a train ticket in a busy station during rush hour is best described as an activity that is:",
    "options": [
      "Routine and highly repetitive",
      "Time-sensitive and stressful",
      "Complex and multi-step",
      "Collaborative and social"
    ],
    "answerIndex": 1,
    "answer": "Time-sensitive and stressful",
    "explanation": "Time pressure and stress fundamentally change how people interact with systems. Under stress, cognitive capacity decreases, attention narrows, and patience evaporates. Users revert to familiar patterns and make more errors. Design must compensate for these human limitations, not expect users to slow down or think carefully.<br><br><strong>Design principles for time-pressured activities:</strong><br>• Minimize steps—every extra tap/click increases abandonment<br>• Use intelligent defaults—most users want the most common option<br>• Make critical actions large and obvious—small targets cause errors under stress<br>• Save progress automatically—users won't remember to save manually<br>• Provide shortcuts for repeat users—saved preferences eliminate decisions<br><br><strong>Example:</strong> At rush hour, commuters buying train tickets face extreme time pressure—their train leaves in 2 minutes, the queue is long, they're carrying bags. Under stress, they can't process complex options or remember details. Design must eliminate friction: prominent buttons for today's date and common destinations, saved payment methods (tap to use last card), smart defaults (off-peak automatically applied if time qualifies), minimal confirmation screens, and contactless payment that completes instantly. No multi-step forms asking for preferences, no tiny text requiring reading, no unclear error messages. Compare this to leisure travel planning at home—users browse options, compare prices, read reviews, adjust dates. Same ticket purchase activity, radically different characteristics requiring opposite design approaches.",
    "shortExplanation": "Buying tickets under time pressure is stressful and urgent."
  },
  {
    "id": 11,
    "section": "2.3",
    "question": "Which activity is most likely to be creative and open-ended?",
    "options": [
      "Editing a video project",
      "Completing a structured online form",
      "Reviewing and approving documents",
      "Searching for specific information"
    ],
    "answerIndex": 0,
    "answer": "Editing a video project",
    "explanation": "Activities exist on a spectrum from highly structured (rigid sequences with clear right answers) to completely open-ended (creative exploration with subjective outcomes). This distinction profoundly affects what good design means. Structured activities need guidance and validation; creative activities need freedom and powerful tools.<br><br><strong>Structured activities:</strong><br>• Clear steps and sequence<br>• Right/wrong answers<br>• Need validation, error prevention<br>• Progress indicators show completion<br>• Examples: forms, checklists, configuration wizards<br><br><strong>Creative activities:</strong><br>• No single correct outcome<br>• Iterative exploration and experimentation<br>• Need powerful tools, easy undo, non-destructive editing<br>• Progress is subjective and evolving<br>• Examples: design, writing, video editing, music composition<br><br><strong>Why this matters:</strong> Applying structured design patterns to creative work frustrates users by constraining exploration. Applying creative patterns to structured work creates confusion—users dont know what to do or whether theyve succeeded.<br><br><strong>Example:</strong> Video editing is deeply creative—users try different cuts, test transitions, experiment with effects, iterate for hours. Theres no singlecorrect' edit. Design must support experimentation: non-destructive editing (try changes without losing originals), unlimited undo/redo, multiple timelines to compare versions, quick preview, and flexible tools that don't enforce a specific workflow. Tax forms are rigidly structured—specific fields, required information, calculations with correct answers, fixed sequence. Design must guide completion: numbered steps showing progress, validation preventing errors ('Tax ID must be 9 digits'), disabled Next buttons until required fields complete, and automatic calculations users can verify but not override. Using video editing patterns for tax forms would leave users lost ('What do I do first? How do I know if I'm done?'). Using form patterns for video editing would straitjacket creativity.",
    "shortExplanation": "Creative activities are exploratory and open-ended, unlike rigid data entry."
  },
  {
    "id": 12,
    "section": "2.3",
    "question": "Why must designers consider whether activities are cooperative or individual?",
    "options": [
      "Because collaborative tasks require different security protocols",
      "Because individual work is more efficient and measurable",
      "Because group work changes communication and coordination needs",
      "Because team activities need more processing power"
    ],
    "answerIndex": 2,
    "answer": "Because group work changes communication and coordination needs",
    "explanation": "Cooperative activities involve multiple people, which introduces coordination, shared awareness and communication requirements.<br><br><strong>Example:</strong> A solo user edits a document alone. A team collaborating on that document needs: real-time presence indicators, commenting, version control, and conflict resolution when two people edit the same paragraph.",
    "shortExplanation": "Group activities need coordination, communication, and shared awareness tools."
  },
  {
    "id": 13,
    "section": "2.4",
    "question": "In PACT, what does context mainly refer to?",
    "options": [
      "The user's prior knowledge and experience level",
      "The system's technical infrastructure and architecture",
      "The physical, social and organisational environments of use",
      "The competitive landscape and market positioning"
    ],
    "answerIndex": 2,
    "answer": "The physical, social and organisational environments of use",
    "explanation": "Context refers to all the environmental factors surrounding use—where activities happen and under what conditions. Many designs fail not because the technology is flawed, but because designers didn't account for the real-world context of use. Context includes three dimensions that interact and constrain design:<br><br><strong>Three types of context:</strong><br>• <strong>Physical:</strong> Light, noise, temperature, space, movement, location (e.g., indoors vs. outdoors, stationary vs. moving)<br>• <strong>Social:</strong> Presence of others, cultural norms, roles, power dynamics, privacy expectations<br>• <strong>Organizational:</strong> Policies, regulations, workflows, hierarchies, compliance requirements<br><br><strong>Why context matters:</strong> The same technology behaves differently in different contexts. A design perfect for quiet office work fails in noisy factories. A design fine for solo use fails in public spaces where others watch. A design acceptable for casual use fails in regulated industries.<br><br><strong>Example:</strong> A doctor using a medical tablet in an emergency room faces intersecting contexts: Physical (harsh overhead lights create screen glare, constant movement and jostling, may be used with gloves), Social (colleagues and patients watching the screen, professional behavior expected, interruptions constant), Organizational (HIPAA privacy regulations, required audit trails, integration with hospital systems, liability concerns). Design must address all three: high-contrast screen readable in bright light, large touch targets usable with gloves, automatic screen timeout to protect privacy when interrupted, encrypted data meeting regulations, simplified workflows for time-critical care. A consumer tablet that works beautifully at home fails here because it wasn't designed for this context.",
    "shortExplanation": "Context includes physical, social, and organizational environments."
  },
  {
    "id": 14,
    "section": "2.4",
    "question": "Which of these is an example of physical context?",
    "options": [
      "Using a phone in bright sunlight",
      "Working within regulatory compliance rules",
      "Following established workplace protocols",
      "Adhering to company security policies"
    ],
    "answerIndex": 0,
    "answer": "Using a phone in bright sunlight",
    "explanation": "Physical context encompasses all tangible environmental conditions that affect interaction—factors designers often forget because they work in comfortable offices. These physical constraints can make or break a design in real use. Ignoring them leads to systems that work on designersdesks but fail in users actual environments.<br><br><strong>Key physical factors:</strong><br>• <strong>Light:</strong> Indoor/outdoor, bright/dim, glare, changing conditions<br>• <strong>Noise:</strong> Quiet offices vs. factory floors, affects audio feedback<br>• <strong>Movement:</strong> Stationary desk vs. walking, driving, exercising<br>• <strong>Space:</strong> Cramped vs. spacious, affecting device size and multitasking<br>• <strong>Conditions:</strong> Temperature (affects screens, batteries), weather, cleanliness (dirty hands, gloves)<br><br><strong>Design implications:</strong> Physical context determines feasible interaction methods. Bright sunlight requires high-contrast displays. Noisy environments rule out audio-only feedback. Movement demands larger touch targets and voice control. Dirty environments need washable surfaces and simplified interfaces usable with gloves.<br><br><strong>Example:</strong> Using a smartphone outdoors in bright sunlight creates severe glare—text becomes invisible against washed-out backgrounds, making the device unusable. This isn't a user problem; it's a design problem. Good design anticipates physical context: automatic brightness boost in sunlight, high-contrast mode with dark text on white backgrounds, larger text to remain readable despite glare, matte screen coatings reducing reflections. Compare to indoor use where subtle colors and smaller text work fine. The same device, different context, requires adaptive design.",
    "shortExplanation": "Physical context includes light, noise, movement, and space."
  },
  {
    "id": 15,
    "section": "2.4",
    "question": "Which scenario best illustrates social context?",
    "options": [
      "Using a device while commuting on crowded public transport",
      "Using a phone during a quiet meeting where speaking is frowned upon",
      "Working on a laptop in a cafe with unreliable Wi-Fi",
      "Accessing a system from a shared workspace with multiple users"
    ],
    "answerIndex": 1,
    "answer": "Using a phone during a quiet meeting where speaking is frowned upon",
    "explanation": "Social context recognizes that technology use doesn't happen in isolation—other people are present, watching, judging, and constraining behavior. Social factors create invisible but powerful design requirements around privacy, appropriateness, and social acceptability. What's fine when alone may be mortifying in public.<br><br><strong>Social dimensions:</strong><br>• <strong>Privacy:</strong> Who can see your screen, hear your interactions?<br>• <strong>Social norms:</strong> What behaviors are appropriate here? (e.g., no phone calls in meetings)<br>• <strong>Power dynamics:</strong> Hierarchy affects what people feel comfortable doing (e.g., junior staff in front of managers)<br>• <strong>Collaboration:</strong> Working with others vs. alone changes coordination needs<br>• <strong>Cultural expectations:</strong> Different cultures have different technology etiquette<br><br><strong>Design implications:</strong> Provide interaction methods appropriate for social situations. Enable privacy protection (privacy screens, discrete notifications). Support both solo and collaborative work. Allow users to control social visibility.<br><br><strong>Example:</strong> During a quiet professional meeting, using your phone creates social tension—others expect attention and participation. Voice commands ('Hey Siri, remind me...') would be incredibly disruptive and inappropriate. Loud notification sounds would be embarrassing. Even glancing at your phone repeatedly signals disengagement. Design must accommodate this social context: silent modes with haptic feedback only, quick glanceable information (no need to unlock or navigate), discrete visual notifications, and gesture-based input that doesn't require speaking. Text-based interaction preserves social appropriateness. Compare to being alone at home where voice commands are convenient and loud notifications are fine—the same action (checking your phone) has completely different social acceptability depending on context.",
    "shortExplanation": "Social context includes norms, roles, and others' expectations."
  },
  {
    "id": 16,
    "section": "2.4",
    "question": "What is an example of organisational context from the chapter?",
    "options": [
      "Working in environments with frequent interruptions",
      "A hospital requiring data confidentiality",
      "Using devices with limited battery life",
      "Accessing systems through slow network connections"
    ],
    "answerIndex": 1,
    "answer": "A hospital requiring data confidentiality",
    "explanation": "Organizational context encompasses the formal structures, rules, and policies that govern how technology can be used within institutions. These constraints are often invisible to consumers but dominate enterprise design. Ignoring organizational context makes systems technically sound but organizationally unusable—they violate policies, disrupt workflows, or create legal liability.<br><br><strong>Organizational factors:</strong><br>• <strong>Regulations:</strong> Legal requirements like HIPAA (healthcare privacy), GDPR (data protection), financial compliance<br>• <strong>Policies:</strong> Internal rules about data handling, security, acceptable use<br>• <strong>Workflows:</strong> Established processes and handoffs between roles<br>• <strong>Hierarchies:</strong> Approval chains, access levels, reporting structures<br>• <strong>Standards:</strong> Industry standards, compatibility requirements, audit trails<br><br><strong>Why this matters:</strong> Organizations can't use systems that violate regulations, no matter how well-designed. Designs that clash with established workflows face resistance. Systems that don't fit organizational structures create confusion about responsibility.<br><br><strong>Example:</strong> A hospital patient records app operates in an intensely regulated organizational context. HIPAA mandates: all patient data encrypted in transit and at rest, detailed access logs showing who viewed what when, automatic session timeouts to prevent unauthorized viewing, role-based access (nurses see different data than doctors), audit trails that can't be deleted. Additionally, hospital policies require: integration with existing record systems, workflows that match admission/discharge/transfer processes, escalation paths for critical alerts. A casual notes app has none of these constraints—no encryption requirements, no audit logs, no role management. The hospital app isnt justmore secure'; its fundamentally shaped by organizational context that doesnt exist for consumer apps. Building one requires understanding the regulatory and organizational environment, not just user needs.",
    "shortExplanation": "Organizational context includes policies, rules, and regulations."
  },
  {
    "id": 17,
    "section": "2.4",
    "question": "Why do systems that work well in a lab often fail in real contexts?",
    "options": [
      "Because lab testing focuses primarily on technical performance",
      "Because lab tests ignore noise, interruptions and social constraints",
      "Because controlled environments eliminate user variability factors",
      "Because lab participants are typically more tech-savvy than average"
    ],
    "answerIndex": 1,
    "answer": "Because lab tests ignore noise, interruptions and social constraints",
    "explanation": "Lab testing creates controlled, idealized conditions that eliminate the very factors that make real-world use challenging. In labs, researchers remove distractions to isolate system performance. But in deployment, those distractions are the actual context of use. Systems that perform flawlessly in labs often fail immediately in reality because the lab stripped away critical contextual factors.<br><br><strong>What labs eliminate:</strong><br>• <strong>Physical:</strong> Noise, poor lighting, movement, weather, space constraints<br>• <strong>Social:</strong> Privacy concerns, interruptions, pressure from others watching<br>• <strong>Organizational:</strong> Time pressure, multitasking, real workflows, integration with other systems<br>• <strong>Emotional:</strong> Stress, fatigue, genuine consequences of errors<br><br><strong>The problem:</strong> Designers see successful lab tests and conclude the system works. But users experience the system in complex, messy contexts. The gap between controlled testing and real deployment causes widespread design failures.<br><br><strong>Lesson for designers:</strong> Test in context. If your system will be used outdoors, test outdoors. If users will be stressed and rushed, test under time pressure. If it's used in noisy environments, test with realistic noise.<br><br><strong>Example:</strong> A ticket kiosk works perfectly in usability lab testing—participants navigate menus easily, complete purchases in 45 seconds, express satisfaction. But deployed in a real train station, the same kiosk fails catastrophically: Sunlight creates glare making the screen barely visible; crowds push from behind, preventing careful reading; station announcements and construction noise make audio feedback inaudible; users rush because their train leaves in 2 minutes; theyre carrying luggage and cant use both hands freely; they're stressed and make errors, then abandon the transaction. Every contextual factor the lab eliminated turns out to be critical. The interface that worked in quiet, controlled conditions fails when noise, pressure, movement, and stress are present. This isn't a deployment problem—it's a testing problem. The lab gave false confidence by removing context.",
    "shortExplanation": "Lab testing misses real-world noise, interruptions, and constraints."
  },
  {
    "id": 18,
    "section": "2.5",
    "question": "In PACT, technologies are defined as:",
    "options": [
      "The tools and systems people use to carry out activities",
      "The software development methodologies and frameworks",
      "The infrastructure and networking equipment available",
      "The programming languages and technical stack chosen"
    ],
    "answerIndex": 0,
    "answer": "The tools and systems people use to carry out activities",
    "explanation": "In PACT, Technologies refer to all the tools and systems that mediate between people and their activities—not just the device, but its entire interaction capability. This includes input methods (how users communicate with the system), output methods (how the system communicates back), processing power, connectivity, and physical form factor. Each technology enables certain interactions while constraining others.<br><br><strong>Why technology shapes design:</strong><br>• Different devices afford different interaction possibilities (a watch supports glances; a keyboard supports extended writing)<br>• Technical constraints create real limits (small screens can't show complex layouts; voice input struggles with technical terminology)<br>• Technologies have inherent strengths (smartphones have cameras and location; desktops have large screens and precision input)<br><br><strong>Key concept—Affordances:</strong> What a technology makes easy, possible, or impossible. A smartwatch affords quick glances but not detailed reading. A keyboard affords rapid text entry but not sketching. Good designers work with affordances, not against them.<br><br><strong>Example:</strong> A smartwatch (1.5\" screen, wrist-worn, always-accessible, touch input only, limited battery) affords: quick glanceable information (time, notifications), simple single-tap interactions, continuous passive monitoring (heart rate, steps), but constrains detailed reading, multi-step tasks, and prolonged active use. A desktop computer (24\" screen, keyboard/mouse, wall-powered, stationary) affords: complex information display, precise manipulation, extended focused work sessions, multitasking across windows, but constrains portability and accessibility while moving. Each technology enables fundamentally different experiences. The same email app must adapt: on watch, show sender and subject for quick triage; on desktop, show full thread with rich editing tools. Ignoring technology constraints leads to designs that fight the device instead of leveraging its strengths.",
    "shortExplanation": "Technologies are the devices, systems, and tools supporting activities."
  },
  {
    "id": 19,
    "section": "2.5",
    "question": "Which of the following is an example of an input modality mentioned in the chapter?",
    "options": [
      "Touch or voice input",
      "Display resolution and refresh rate",
      "Processing speed and memory capacity",
      "Network connectivity and bandwidth"
    ],
    "answerIndex": 0,
    "answer": "Touch or voice input",
    "explanation": "Input modalities are the methods users employ to communicate information, commands, and content to systems. The choice of input modality profoundly affects usability because different modalities suit different activities, contexts, and user capabilities. No single input method works universally—each has contexts where it excels and contexts where it fails.<br><br><strong>Common input modalities:</strong><br>• <strong>Touch:</strong> Direct, intuitive, but requires looking and free hands; struggles with precision<br>• <strong>Voice:</strong> Hands-free, fast for dictation, but fails in noise or social situations; poor for technical/numeric input<br>• <strong>Keyboard:</strong> Rapid text entry, precise, but requires dedicated attention and both hands<br>• <strong>Mouse/trackpad:</strong> Precise pointing and selection, but requires desk/flat surface<br>• <strong>Gestures:</strong> Natural physical movements, but tiring (gorilla arm), culturally variable<br>• <strong>Gaze:</strong> Fast target selection, but imprecise, tiring, unintentional activation<br><br><strong>Design principle:</strong> Match modality to context. Hands busy? Use voice. Socially inappropriate to speak? Use touch/gesture. High precision needed? Provide mouse/stylus.<br><br><strong>Example:</strong> Voice input excels while driving—eyes on road, hands on wheel, car noise-cancellation enables speech recognition. Voice fails in quiet meetings (socially inappropriate), loud factories (recognition fails), or for passwords (shoulder surfing risk). Touch input works in loud construction sites where voice fails, but not while wearing thick gloves or in extreme cold (screens unresponsive). Keyboard input enables rapid writing of complex technical content with symbols, but is useless while walking or with injured hands. Good design provides appropriate modalities for each situation, often offering multiple inputs: a navigation app supporting voice (Take me home), touch (tap destination), and keyboard (type address) lets users choose based on their current context.",
    "shortExplanation": "Input modalities are ways users provide information: touch, voice, typing, gestures."
  },
  {
    "id": 20,
    "section": "2.5",
    "question": "Which statement best describes the relationship between technology and UX in PACT?",
    "options": [
      "Technology capabilities should match user skill levels",
      "Different technologies afford different kinds of interactions",
      "Advanced technology always improves user experience",
      "Technology selection depends primarily on cost"
    ],
    "answerIndex": 1,
    "answer": "Different technologies afford different kinds of interactions",
    "explanation": "The relationship between technology and experience is not that better technology creates better experiences but that different technologies afford fundamentally different kinds of interactions. A technology's physical form, input/output capabilities, and constraints shape what activities are feasible and how users must adapt their behavior. Understanding these affordances prevents designers from forcing inappropriate interactions onto unsuitable technologies.<br><br><strong>The concept of affordances:</strong> What a technology naturally enables or suggests. A button affords pressing. A touch screen affords direct manipulation. A tiny screen affords glancing but not detailed work. Designers should work with affordances, making easy what the technology does well and avoiding what it does poorly.<br><br><strong>Why this matters:</strong> Trying to replicate desktop experiences on watches fails because the technologies afford different interactions. Success comes from designing for each technology's unique strengths and constraints, not fighting them.<br><br><strong>Example comparison:</strong> Smartwatch affords ambient awareness (always-on, glanceable, worn on body), quick micro-interactions (single tap, swipe), passive monitoring (sensors track activity 24/7), but constrains detailed information display, extended active use, complex input. Phone affords personal detailed interaction (hand-held focus, larger screen), capturing moments (camera), mid-length tasks (5-15 minutes), but constrains always-on awareness, two-handed work, extended typing. Desktop affords immersive deep work (large screen, comfortable posture, multiple windows), precision manipulation (mouse), professional creation (video editing, coding), but constrains portability, casual use, and quick access. VR affords spatial presence and 3D manipulation but constrains text reading, social acceptability, and extended comfort. Each technology creates distinct experience possibilities. The same email inbox adapts: watch shows 'You have 3 new emails' with sender names; phone shows subject lines and first lines; desktop shows full threaded conversation with folders and search. Trying to put the desktop experience on the watch would fail because the technology doesn't afford it.",
    "shortExplanation": "Different technologies enable different interaction possibilities."
  },
  {
    "id": 21,
    "section": "2.5",
    "question": "Why is a smartwatch display a design constraint in PACT terms?",
    "options": [
      "Its small screen limits how much information can be shown at once",
      "It requires constant connection to a paired smartphone device",
      "Its battery life restricts continuous usage and functionality",
      "Its input methods are limited to simple gestures and taps"
    ],
    "answerIndex": 0,
    "answer": "Its small screen limits how much information can be shown at once",
    "explanation": "Small display size restricts layout, density of information and interaction possibilities.<br><br><strong>Example:</strong> A smartwatch can show 'Meeting in 5 min' but not your full calendar. Designers must prioritize: show only essential info, use notifications, allow drill-down to phone for details.",
    "shortExplanation": "Small screens limit information density and layout options."
  },
  {
    "id": 22,
    "section": "2.5",
    "question": "Why must designers consider connectivity as part of technology in PACT?",
    "options": [
      "Connectivity determines the visual quality of media content",
      "Connectivity affects the speed of interface animations",
      "Connectivity influences server-side processing capabilities",
      "Unstable or offline conditions change what the system can reliably do"
    ],
    "answerIndex": 3,
    "answer": "Unstable or offline conditions change what the system can reliably do",
    "explanation": "Connectivity is not binary (online/offline) but exists on a spectrum from fast reliable networks to slow intermittent connections to completely offline. Many designs assume constant fast connectivity because designers work in offices with excellent Wi-Fi. But users experience variable connectivity, and systems that depend on the network fail catastrophically when connections drop. Connectivity constraints fundamentally change what the system can do.<br><br><strong>Connectivity states and implications:</strong><br>• <strong>Fast, stable:</strong> Stream video, sync continuously, assume instant responses<br>• <strong>Slow but stable:</strong> Pre-load content, minimize requests, show progress indicators<br>• <strong>Intermittent:</strong> Queue actions to retry, distinguish local vs. server state, handle conflicts<br>• <strong>Offline:</strong> Provide cached content, local-only features, clear limitations messaging<br><br><strong>Common design failures:</strong> Apps that freeze waiting for network responses; forms that lose data if connection drops mid-submission; systems with no indication of connection state; apps completely unusable offline even for local content.<br><br><strong>Better approach:</strong> Design for offline first—make core features work locally, sync in background when possible, show connection state clearly, handle conflicts gracefully.<br><br><strong>Example:</strong> A navigation app is useless offline if it hasn't pre-loaded maps—no network means no directions, stranding users when they need help most (in unfamiliar areas without connectivity). Good design anticipates this: allow downloading maps for regions in advance, cache recent routes, enable offline search of saved locations, show clearly when in offline mode ('Using offline maps, no traffic data'), automatically sync routes and searches when connection returns. Users can still navigate to saved addresses using cached maps. Similarly, a note-taking app should work fully offline—write notes locally, auto-save to device, sync to cloud when connected—rather than blocking all editing without network. The best connectivity design is invisible: the app works smoothly regardless of connection state, with users only noticing limitations (live traffic unavailable) rather than complete failure.",
    "shortExplanation": "Poor connectivity changes what features work reliably."
  },
  {
    "id": 23,
    "section": "2.6",
    "question": "What is the main purpose of scoping a problem using PACT?",
    "options": [
      "To create detailed technical implementation documentation",
      "To define the boundaries and opportunities of the design problem",
      "To establish project timelines and resource allocation",
      "To generate initial wireframes and visual mockups"
    ],
    "answerIndex": 1,
    "answer": "To define the boundaries and opportunities of the design problem",
    "explanation": "Scoping with PACT clarifies who, what, where and with what tools, so the design problem is properly framed.<br><br><strong>Example:</strong> Vague: 'Build a better shopping app.' Scoped with PACT: Who (busy parents), What (quick reorders of weekly groceries), Where (home, noisy kitchens), With what (smartphones with poor Wi-Fi). Now requirements are clear.",
    "shortExplanation": "Scoping defines who, what, where, and with what—framing the problem clearly."
  },
  {
    "id": 24,
    "section": "2.6",
    "question": "In the train-ticket kiosk example, which PACT element does 'commuters, tourists, elderly, disabled users' belong to?",
    "options": [
      "Activities",
      "People",
      "Contexts",
      "Technologies"
    ],
    "answerIndex": 1,
    "answer": "People",
    "explanation": "These describe different user groups, so they are part of the People element.<br><br><strong>Example:</strong> Kiosk users: commuters (rushed, frequent), tourists (unfamiliar, need guidance), elderly (slower, larger text), disabled (wheelchair height, audio support). Each group has different People characteristics.",
    "shortExplanation": "User groups belong to the People element."
  },
  {
    "id": 25,
    "section": "2.6",
    "question": "In the same example, 'noisy station, time pressure, queues' refer mainly to:",
    "options": [
      "Activities",
      "Contexts",
      "Technologies",
      "People"
    ],
    "answerIndex": 1,
    "answer": "Contexts",
    "explanation": "Noise, pressure and queues are aspects of the physical and social context of use.<br><br><strong>Example:</strong> A noisy station (can't hear audio), time pressure (need fast checkout), queues (stress, impatience). These context factors demand: visual feedback, defaults, progress indicators, and simple flows.",
    "shortExplanation": "Environmental conditions are part of Contexts."
  },
  {
    "id": 26,
    "section": "2.6",
    "question": "'Select route, pay quickly, find platform info' in the kiosk example are:",
    "options": [
      "Technologies",
      "Contexts",
      "Organisational factors",
      "Activities"
    ],
    "answerIndex": 3,
    "answer": "Activities",
    "explanation": "These describe the tasks users must perform—i.e., activities.<br><br><strong>Example:</strong> Kiosk activities: select destination (browse or search), choose ticket type (single, return), pay (card, contactless), get confirmation (print or digital). Each activity needs clear UI support.",
    "shortExplanation": "Tasks users perform are Activities."
  },
  {
    "id": 27,
    "section": "2.6",
    "question": "Why does the chapter describe PACT as the backbone of human-centred design?",
    "options": [
      "Because it replaces all other design methods",
      "Because it grounds design in real people, activities, contexts and technologies",
      "Because it only focuses on technology performance",
      "Because it eliminates the need for evaluation"
    ],
    "answerIndex": 1,
    "answer": "Because it grounds design in real people, activities, contexts and technologies",
    "explanation": "PACT ensures design is rooted in who is doing what, where, and with what tools, which is central to human-centred design.<br><br><strong>Example:</strong> Human-centred design means understanding actual users in real situations. PACT forces designers to ask: Who will use this? Doing what? Where? With what? This grounds design in reality, not assumptions.",
    "shortExplanation": "PACT ensures design is rooted in real-world people, activities, contexts, and tools."
  },
  {
    "id": 28,
    "section": "2.6",
    "question": "Which question corresponds to the People part of PACT when scoping a problem?",
    "options": [
      "What devices will be supported?",
      "What tasks need to be completed?",
      "Where will the system be used?",
      "Who are we designing for?"
    ],
    "answerIndex": 3,
    "answer": "Who are we designing for?",
    "explanation": "'Who are we designing for?' is the core People question.<br><br><strong>Example:</strong> Designing a health app: Are we designing for young athletes tracking performance? Elderly patients managing medications? Doctors viewing records? Each who drives different requirements.",
    "shortExplanation": "'Who are we designing for?' identifies user groups and their characteristics."
  },
  {
    "id": 29,
    "section": "2.6",
    "question": "Which question corresponds to the Activities part of PACT?",
    "options": [
      "What must users accomplish?",
      "Who are the primary stakeholders?",
      "Where will interaction occur?",
      "What devices are available?"
    ],
    "answerIndex": 0,
    "answer": "What must users accomplish?",
    "explanation": "Activities are about what users need to achieve.<br><br><strong>Example:</strong> Users must accomplish: finding a product, comparing prices, adding to cart, checking out, tracking delivery. Listing activities helps prioritize features.",
    "shortExplanation": "'What must users accomplish?' defines goals and tasks."
  },
  {
    "id": 30,
    "section": "2.6",
    "question": "Which question corresponds to the Contexts part of PACT?",
    "options": [
      "What are the user's goals and motivations?",
      "What tasks need to be supported by the system?",
      "Where and under what conditions does this take place?",
      "What input methods will be provided?"
    ],
    "answerIndex": 2,
    "answer": "Where and under what conditions does this take place?",
    "explanation": "Contexts are about where and under what conditions activities happen.<br><br><strong>Example:</strong> Where: outdoors (sun glare), moving vehicles (bumpy), public spaces (privacy concerns), poor signal (offline mode needed). Conditions shape technical requirements.",
    "shortExplanation": "'Where and under what conditions?' identifies environmental factors."
  },
  {
    "id": 31,
    "section": "2.6",
    "question": "Which question corresponds to the Technologies part of PACT?",
    "options": [
      "What environmental factors affect usage?",
      "What tools and devices are available or possible?",
      "What are the user's characteristics?",
      "What workflows need to be supported?"
    ],
    "answerIndex": 1,
    "answer": "What tools and devices are available or possible?",
    "explanation": "Technologies are the tools and devices that support the activities.<br><br><strong>Example:</strong> Available technologies: smartphones (GPS, camera, touch), wearables (sensors, small screen), desktops (large display, keyboard). Each tool offers different capabilities to leverage.",
    "shortExplanation": "'What tools and devices?' determines technical possibilities and constraints."
  }
]